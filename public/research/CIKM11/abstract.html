<h2>Accounting for Data Dependencies within a Hierarchical Dirichlet Process Mixture Model</h2>
<h3>Dongwoo Kim and Alice Oh</h3>
<h3>To be published in the Proceedings of ACM CIKM 2011</h3>
We propose a hierarchical nonparametric topic model, based on the hierarchical Dirichlet process (HDP), that accounts for dependencies among the data. The HDP mixture models are useful for discovering an unknown semantic structure (i.e., topics) from a set of unstructured data such as a corpus of documents. For simplicity, HDP makes an exchangeability assumption that any permutation of the data points would result in the same joint probability of the data being generated. This exchangeability assumption poses a problem for some domains where there are clear and strong dependencies among the data. An example of such domain is the academic conference proceedings with clear temporal patterns where two articles near each other in publication date are more likely to be about similar topics, compared to two articles far apart in publication date. A model that allows for non-exchangeability of data can capture these dependencies and assign higher probabilities to clusters that account for data dependencies, for example, inferring topics that reflect the temporal patterns of the data. Our model incorporates the distance dependent Chinese restaurant process (ddCRP), which clusters data with an inherent bias toward clusters of data points that are near to one another, into a hierarchical construction analogous to the HDP, and we call this new prior the distance dependent Chinese restaurant franchise (ddCRF). When tested with temporal datasets, the ddCRF mixture model shows clear improvements in data fit compared to the HDP in terms of heldout likelihood and complexity. The resulting set of topics shows the sequential emergence and disappearance patterns of topics. Finally, the per-document topic proportions, used as input to publication time period classification, show better prediction accuracies than the HDP.
